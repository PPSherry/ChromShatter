{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我如何提取这种文件中的这类图片，以及样本名信息和CN等数据呢？一共有几百页，人工去做提取的耗时很大。我需要从这类pdf文件里提取我所需要的训练模型的图片和信息，如何自动化的完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取SV断点图\n",
    "四个SV断点图的坐标，x坐标以染色体区间的两端为准，y坐标以上下两条界线为准; 每一页内的顺序为，先左上 -> 右上 -> 左下 -> 右下\n",
    "* 此前我只用了几页原PDF文件来确定SV图像的坐标，但当应用于整个pdf文件之后，SV图像的坐标却发生了变化\n",
    "* 直接使用原PDF文件产生的每一页的图像（是的，PDF子集中同一页坐标和PDF原件同一页坐标是不一样的），来确定每一个需要切割的SV的坐标后运行符合预期\n",
    "* 建议：根据原PDF文件转换后的图片，确定SV坐标，更改coordinates以及w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 将PDF文件转换为图片\n",
    "def convert_pdf_to_images(pdf_path, output_dir, dpi=300):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "\n",
    "    for i, page in enumerate(pages):\n",
    "        page_filename = f\"{output_dir}/page_{i+1}.png\"\n",
    "        page.save(page_filename, \"PNG\")\n",
    "        print(f\"Saved page as image: {page_filename}\")\n",
    "\n",
    "# 根据手动确定的SV图像坐标，为每一页切割出4个SV断点图\n",
    "def extract_sv_image_from_page(image_path, output_dir, coordinates):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    for idx, (x, y) in enumerate(coordinates):\n",
    "        w, h = 1050, 320\n",
    "        cropped_img = img[y:y+h, x:x+w]\n",
    "        output_filename = f\"{output_dir}/{os.path.splitext(os.path.basename(image_path))[0]}_part_{idx+1}.png\"\n",
    "        cv2.imwrite(output_filename, cropped_img)\n",
    "        print(f\"Saved cropped SV image: {output_filename}\")\n",
    "\n",
    "\n",
    "# 设置文件路径\n",
    "pdf_path = \"/Users/xurui/back_up_unit/天津大学文件/本科毕设相关/Article/high-confidence.pdf\"\n",
    "page_output_dir = \"/Volumes/T7-shield/CS-Bachelor-Thesis/CNN_model/pdf_convert\"\n",
    "image_output_dir = \"/Volumes/T7-shield/CS-Bachelor-Thesis/CNN_model/test-picture\"\n",
    "\n",
    "# 将PDF文件转换为图片\n",
    "convert_pdf_to_images(pdf_path, page_output_dir)\n",
    "\n",
    "coordinates = [\n",
    "    (71, 150),\n",
    "    (1290, 150),\n",
    "    (71, 2005),\n",
    "    (1290, 2005)\n",
    "]\n",
    "\n",
    "if not os.path.exists(image_output_dir):\n",
    "    os.makedirs(image_output_dir)\n",
    "\n",
    "for page_file in os.listdir(page_output_dir):\n",
    "    if page_file.endswith(\".png\"):\n",
    "        page_path = os.path.join(page_output_dir, page_file)\n",
    "        extract_sv_image_from_page(page_path, image_output_dir, coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取文本信息\n",
    "使用 extract_text_info_from_PDF.py 实现，提取样本名，Position, Oscillating CN （2 and 3 states） CN segments\n",
    "* 需要注意的地方：\n",
    "    * 为了避免OCR图片带来的错误，选择直接从PDF文件中提取文本部分\n",
    "    * 页面之间四个染色体破裂事件的分布，并不是完全一样的（_都是左上角的事件，文本部分坐标kennel有细微差别_），所以划分区间的时候需要注意，可以稍微大一些\n",
    "    * 算法中匹配样本名时发现，PCAWG原始表格中短横线 (-) 有多种类型，需要额外注意！\n",
    "* 实现的算法：\n",
    "    1. 先将每一页的文本都提取出来，包括文本和坐标（放在字典里），坐标用于划分到不同的事件中\n",
    "    2. 用其他脚本，手动确定每个事件的大概范围，制作文字部分区间\n",
    "    3. 同一文字区间的文本视为同一个事件的信息\n",
    "    4. 匹配所需要的信息（例如样本名，POS），方法比较复杂，不同信息提取方式也略有不同\n",
    "        * 样本名是使用PCAWG提供表格中 donor_idx 进行匹配  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用PCAWG人工审查结果打标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于提取PDF时缺失的值，根据PCAWG的表格中的数据进行补充  \n",
    "PCAWG表格和我们提取的表格之间，列的映射关系：\n",
    "* CN segments -> cn_segments\n",
    "* Nb. oscillating.CN -> CN_2_states\n",
    "* Nb. oscillaring CN 3 states -> CN_3_states\n",
    "* Chr + Start + End -> position\n",
    "* donor_idx -> sample_name\n",
    "    * 提取PDF中 sample_name 时出现了 (-) 不匹配PCAWG表格中 (-) 的问题，故提取信息的表格中使用的sample_name不是直接从PDF中提取的，而是使用PCAWG表格中对应的 donor_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total rows in input file: 1136  \n",
    "Rows with missing values: 21  \n",
    "Missing values by column:  \n",
    "  position: 21 missing values  \n",
    "  \n",
    "即只存在position列没有提取成功的情况 [经确认，是正则匹配时忽略了X染色体的情况，修改后已无缺失值]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查PCAWG的注释条目是否存在于 high-confidence PDF文件中  \n",
    "即，high-confidence 中的事件是否已经去除人工审查为 False Postive 的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 第一步: 处理combined_events.tsv ===\n",
      "位置拆分完成，成功: 1136, 失败: 0\n",
      "拆分结果已保存到 /Volumes/T7-shield/CS-Bachelor-Thesis/CNN_model/text_info_from_PDF/combined_events_split.tsv\n",
      "\n",
      "=== 第二步: 查找匹配记录 ===\n",
      "\n",
      "总计找到 0 条匹配记录\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def split_position(position_str):\n",
    "    \"\"\"\n",
    "    将位置字符串(Chr:Start-End)拆分为三个组件\n",
    "    \"\"\"\n",
    "    if not isinstance(position_str, str) or not position_str:\n",
    "        return None, None, None\n",
    "        \n",
    "    # 使用正则表达式匹配位置格式\n",
    "    match = re.match(r'([0-9XY]+):(\\d+)[−-](\\d+)', position_str)\n",
    "    if match:\n",
    "        chr_val = match.group(1)\n",
    "        start_val = int(match.group(2))\n",
    "        end_val = int(match.group(3))\n",
    "        return chr_val, start_val, end_val\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "def process_combined_events(tsv_path):\n",
    "    \"\"\"\n",
    "    处理combined_events.tsv文件，拆分position列\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取TSV文件\n",
    "        df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        \n",
    "        # 检查position列是否存在\n",
    "        if 'position' not in df.columns:\n",
    "            print(f\"错误: {tsv_path}中没有'position'列\")\n",
    "            return None\n",
    "            \n",
    "        # 创建新列存储拆分结果\n",
    "        df['Chr'] = None\n",
    "        df['Start'] = None\n",
    "        df['End'] = None\n",
    "        \n",
    "        # 拆分每一行的position\n",
    "        failure_count = 0\n",
    "        for idx, row in df.iterrows():\n",
    "            chr_val, start_val, end_val = split_position(row['position'])\n",
    "            if chr_val is None:\n",
    "                failure_count += 1\n",
    "                print(f\"警告: 无法拆分position值 '{row['position']}' (行 {idx+2})\")\n",
    "            else:\n",
    "                df.at[idx, 'Chr'] = chr_val\n",
    "                df.at[idx, 'Start'] = start_val\n",
    "                df.at[idx, 'End'] = end_val\n",
    "        \n",
    "        print(f\"位置拆分完成，成功: {len(df) - failure_count}, 失败: {failure_count}\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"处理{tsv_path}时出错: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def find_matching_records(combined_df, abnormal_path):\n",
    "    \"\"\"\n",
    "    查找abnormal_calls_from_PCAWG.tsv中与combined_events.tsv匹配的记录\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取abnormal文件\n",
    "        abnormal_df = pd.read_csv(abnormal_path, sep='\\t')\n",
    "        \n",
    "        # 检查必要的列是否存在\n",
    "        required_cols = ['donor_idx', 'Chr', 'Start', 'End']\n",
    "        for col in required_cols:\n",
    "            if col not in abnormal_df.columns:\n",
    "                print(f\"错误: {abnormal_path}中缺少'{col}'列\")\n",
    "                return\n",
    "        \n",
    "        # 确保数据类型一致\n",
    "        combined_df['Chr'] = combined_df['Chr'].astype(str)\n",
    "        combined_df['Start'] = pd.to_numeric(combined_df['Start'], errors='coerce')\n",
    "        combined_df['End'] = pd.to_numeric(combined_df['End'], errors='coerce')\n",
    "        \n",
    "        abnormal_df['Chr'] = abnormal_df['Chr'].astype(str)\n",
    "        abnormal_df['Start'] = pd.to_numeric(abnormal_df['Start'], errors='coerce')\n",
    "        abnormal_df['End'] = pd.to_numeric(abnormal_df['End'], errors='coerce')\n",
    "        \n",
    "        # 遍历abnormal文件中的每一行\n",
    "        match_count = 0\n",
    "        for idx, abnormal_row in abnormal_df.iterrows():\n",
    "            # 查找匹配记录\n",
    "            matches = combined_df[\n",
    "                (combined_df['sample_name'] == abnormal_row['donor_idx']) &\n",
    "                (combined_df['Chr'] == abnormal_row['Chr']) &\n",
    "                (combined_df['Start'] == abnormal_row['Start']) &\n",
    "                (combined_df['End'] == abnormal_row['End'])\n",
    "            ]\n",
    "            \n",
    "            if len(matches) > 0:\n",
    "                match_count += 1\n",
    "                print(f\"\\n匹配记录 #{match_count}:\")\n",
    "                print(f\"  Abnormal记录 (行 {idx+2}):\")\n",
    "                print(f\"    donor_idx: {abnormal_row['donor_idx']}\")\n",
    "                print(f\"    Chr: {abnormal_row['Chr']}\")\n",
    "                print(f\"    Start: {abnormal_row['Start']}\")\n",
    "                print(f\"    End: {abnormal_row['End']}\")\n",
    "                \n",
    "                for _, match in matches.iterrows():\n",
    "                    print(f\"  匹配的Combined记录:\")\n",
    "                    print(f\"    sample_name: {match['sample_name']}\")\n",
    "                    print(f\"    position: {match['position']}\")\n",
    "                    print(f\"    Chr: {match['Chr']}\")\n",
    "                    print(f\"    Start: {match['Start']}\")\n",
    "                    print(f\"    End: {match['End']}\")\n",
    "                    if 'oscillating_cn_2&3_states' in match:\n",
    "                        print(f\"    oscillating_cn: {match['oscillating_cn_2&3_states']}\")\n",
    "                    if 'cn_segments' in match:\n",
    "                        print(f\"    cn_segments: {match['cn_segments']}\")\n",
    "        \n",
    "        print(f\"\\n总计找到 {match_count} 条匹配记录\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理{abnormal_path}时出错: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # 设置文件路径\n",
    "    base_dir = \"/Volumes/T7-shield/CS-Bachelor-Thesis/CNN_model\"\n",
    "    combined_path = os.path.join(base_dir, \"text_info_from_PDF/combined_events.tsv\")\n",
    "    abnormal_path = os.path.join(base_dir, \"PCAWG-related/abnormal_calls_from_PCAWG.tsv\")\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    for path in [combined_path, abnormal_path]:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"错误: 文件 {path} 不存在\")\n",
    "            return\n",
    "    \n",
    "    # 第一步: 处理combined_events.tsv，拆分position列\n",
    "    print(\"=== 第一步: 处理combined_events.tsv ===\")\n",
    "    combined_df = process_combined_events(combined_path)\n",
    "    if combined_df is None:\n",
    "        return\n",
    "    \n",
    "    # 保存拆分后的结果（可选）\n",
    "    output_path = os.path.join(base_dir, \"text_info_from_PDF/combined_events_split.tsv\")\n",
    "    combined_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"拆分结果已保存到 {output_path}\")\n",
    "    \n",
    "    # 第二步: 查找匹配记录\n",
    "    print(\"\\n=== 第二步: 查找匹配记录 ===\")\n",
    "    find_matching_records(combined_df, abnormal_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
